{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breast_cancer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcWS-dxReSDg",
        "outputId": "a9ddd912-7e64-4866-e439-b9fb56e3260b"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers,activations,losses,models,backend\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import csv\r\n",
        "\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnP5yx-Afi5U"
      },
      "source": [
        "data = pd.DataFrame()\r\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/vikram0230/Cancer-Prediction/master/data.csv\")"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpG2qKRSg6cA"
      },
      "source": [
        "data.dropna(axis=1, inplace=True)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbmLtl0ngKIj"
      },
      "source": [
        "data.drop(labels='id',axis=1,inplace=True)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "itxnWt4eiBqf",
        "outputId": "9e90447d-3612-42a9-b51e-fd2b5ee03fb8"
      },
      "source": [
        "data"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0           M        17.99  ...          0.4601                  0.11890\n",
              "1           M        20.57  ...          0.2750                  0.08902\n",
              "2           M        19.69  ...          0.3613                  0.08758\n",
              "3           M        11.42  ...          0.6638                  0.17300\n",
              "4           M        20.29  ...          0.2364                  0.07678\n",
              "..        ...          ...  ...             ...                      ...\n",
              "564         M        21.56  ...          0.2060                  0.07115\n",
              "565         M        20.13  ...          0.2572                  0.06637\n",
              "566         M        16.60  ...          0.2218                  0.07820\n",
              "567         M        20.60  ...          0.4087                  0.12400\n",
              "568         B         7.76  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFv8s9b6iPNI"
      },
      "source": [
        "values = data.drop(labels='diagnosis',axis=1)\r\n",
        "targets = data.diagnosis"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n02jJoCiiHv"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(values,targets,test_size=0.2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJBvJ9MMjpxP"
      },
      "source": [
        "encoder = LabelEncoder()\r\n",
        "encoder.fit(y_train)\r\n",
        "y_encoded_train = encoder.fit_transform(y_train)\r\n",
        "y_encoded_test = encoder.fit_transform(y_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDCxQS2qNl2c",
        "outputId": "e7ee9c6f-1c2f-4923-e9c1-7f13c9841d5b"
      },
      "source": [
        "x_train.shape[1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XsZxezDktT0"
      },
      "source": [
        "def create_model(layers,activation):\r\n",
        "  model = models.Sequential()\r\n",
        "  for i,nodes in enumerate(layers):\r\n",
        "    print(nodes)\r\n",
        "    if i==0:\r\n",
        "      pass\r\n",
        "      model.add(Dense(nodes, input_shape=[x_train.shape[1]], activation=activation))\r\n",
        "    else:\r\n",
        "      model.add(Dense(nodes, activation=activation))\r\n",
        "\r\n",
        "  model.add(Dense(1))\r\n",
        "  model.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=['accuracy'])\r\n",
        "  return model\r\n",
        "\r\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaGtWhw5N4Fg"
      },
      "source": [
        "layers = [[20],[64],[64,32],[64,64],[64,32,32],[64,64,32]]\r\n",
        "activations = ['relu', 'sigmoid']\r\n",
        "param_grid = dict(layers=layers,activation=activations,epochs=[30], batch_size=[50,20,100])\r\n",
        "\r\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "byfUKx97TR4d",
        "outputId": "5db74551-f83c-4a75-8c7d-7a8a0dc66e2b"
      },
      "source": [
        "grid.fit(x_train,y_train)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a9ba7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.0851 - accuracy: 0.6703\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a956c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53af528268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53ae3266a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 4.5766 - accuracy: 0.7033\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53ae326a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.5275\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.6593\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8791\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8791\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8846\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8846\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.9011\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9011\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.8984\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9038\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9066\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9093\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8956\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.9011\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9093\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9148\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9148\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.9148\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9148\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9093\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9093\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9093\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9066\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9066\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9066\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9148\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9066\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9176\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9011\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9093\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a83ea7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.4103 - accuracy: 0.9011\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a982bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4819 - accuracy: 0.4835\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6374\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6236\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.6703\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7857\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8736\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8874\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8709\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8709\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8846\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8846\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8984\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.8984\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8956\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.9011\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.9011\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.8956\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8984\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.9093\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.9038\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.9011\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.9038\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.8984\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.8956\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8984\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.9066\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9203\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9203\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.9093\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.9176\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a510f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9451\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9160 - accuracy: 0.4588\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7390 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5989\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.7005\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7692\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.8132\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7747\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.8352\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.8571\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8654\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8599\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8709\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8846\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8791\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8956\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8956\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8984\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8984\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.9011\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8819\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8764\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9066\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9066\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9203\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.8984\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9011\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9066\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9066\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9176\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9066\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539f5768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9231\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d95b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1071 - accuracy: 0.3984\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5165\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6016\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6016\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6016\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6016\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6016\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6016\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6044\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.6099\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.6209\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7060\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.8681\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8681\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8819\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8846\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8819\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8984\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8984\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.9011\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.9038\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.9011\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8929\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8984\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.8984\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9011\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9093\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9231\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.9093\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8984\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539dbcf7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.8571\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7802\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.8626\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8654\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8736\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8846\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8819\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8901\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.9038\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.8984\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9093\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.9093\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.8956\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.9093\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.9176\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9038\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9121\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9066\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.8956\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.9148\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9093\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9121\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9148\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1922 - accuracy: 0.9176\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53adf20048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.9121\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.6566\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8352\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7418\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8489\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8819\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8846\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8846\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8929\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8846\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8874\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8984\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8901\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8874\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2430 - accuracy: 0.8929\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.8901\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.8929\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.8874\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.8984\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.8984\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.8956\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9038\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9011\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9038\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.8956\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.8984\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9121\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1931 - accuracy: 0.9176\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53ae19bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.9451\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.5275\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.5934\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5934\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.5934\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.5934\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.5934\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7473\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.6319\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.5934\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7857\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.8764\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8819\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.8874\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8819\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8901\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.9121\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8846\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.9176\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.9176\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9231\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9066\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9258\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9341\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1684 - accuracy: 0.9341\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2094 - accuracy: 0.9368\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.9341\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53ae3266a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.9011\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.6099\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7830\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.8571\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8352\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8407\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8654\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8764\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8681\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8764\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.8984\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8764\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8819\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.9038\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8956\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8984\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.8956\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2577 - accuracy: 0.8901\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8901\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9038\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0820 - accuracy: 0.7610\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8083 - accuracy: 0.6621\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7582\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.9011\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.9148\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.9093\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53adb52ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.9011\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.7033\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.8104\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.6016\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.8791\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8846\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8819\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.9011\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8984\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.9011\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2775 - accuracy: 0.8956\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2410 - accuracy: 0.8984\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8929\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.8984\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9176\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9121\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2425 - accuracy: 0.9148\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9121\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8379\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8075 - accuracy: 0.4286\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7363\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.9148\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.9121\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.9038\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.9038\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9038\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9038\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.9038\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9066\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9066\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2191 - accuracy: 0.9093\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53ae3ad598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8901\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53af530e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8700 - accuracy: 0.4341\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.6209\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.6209\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.6593\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8791\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8929\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8901\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8901\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8874\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8709\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8929\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.8984\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9011\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.8929\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3209 - accuracy: 0.8956\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8956\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8984\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3778 - accuracy: 0.8462\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.4945\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.4258\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7555\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8929\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8956\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.9011\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8956\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.8929\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53af4f2d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9451\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8411 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.4313\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7085 - accuracy: 0.4066\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6978\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6124 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.6154\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.8104\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7610\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.8214\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8434\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.8544\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8681\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8846\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8736\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8626\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8709\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8874\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8984\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.8874\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9038\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.9038\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.9038\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.9121\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9066\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.9066\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9203\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.9011\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.9121\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a9941d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.9121\n",
            "20\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53af41c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "20\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.9711 - accuracy: 0.6016\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1086 - accuracy: 0.6016\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1080 - accuracy: 0.6016\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1077 - accuracy: 0.6016\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1069 - accuracy: 0.6016\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1065 - accuracy: 0.6016\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1062 - accuracy: 0.6016\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1060 - accuracy: 0.6016\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1058 - accuracy: 0.6016\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1055 - accuracy: 0.6016\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.9110 - accuracy: 0.6016\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.8303 - accuracy: 0.6154\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.6429\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7088\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7692\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8077\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8132\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8159\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.8516\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8544\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8544\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8654\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8544\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8571\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8654\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8681\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8846\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8764\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8819\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8681\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a9759488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8571\n",
            "20\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 8.7139 - accuracy: 0.4286\n",
            "20\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "20\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.0253 - accuracy: 0.4038\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.7717 - accuracy: 0.4011\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.5302\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5797\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5824\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5824\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5824\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5852\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5824\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5879\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5852\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5852\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5852\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5879\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5879\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5824\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5879\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5852\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5879\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5879\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5879\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5879\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5879\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5852\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5852\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5907\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.5907\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5907\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5934\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6923\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.8753 - accuracy: 0.7033\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.7370 - accuracy: 0.8626\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8819\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.9038\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8984\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8984\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.9148\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.8407\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.9038\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8846\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.9148\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.9148\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.9093\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.9176\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.9176\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.9066\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.9286\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.9231\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9148\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.9176\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9176\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9121\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9203\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9203\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9176\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9148\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9148\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9286\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.9231\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9258\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.9011\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 9.1917 - accuracy: 0.3984\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 9.1747 - accuracy: 0.3984\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.2220 - accuracy: 0.3297\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 4.0813 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.9927 - accuracy: 0.6429\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.8077\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.6676\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.4510 - accuracy: 0.3819\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.1114 - accuracy: 0.3736\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.0430 - accuracy: 0.3681\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.9773 - accuracy: 0.3736\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.9229 - accuracy: 0.3791\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.8754 - accuracy: 0.3874\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.8329 - accuracy: 0.4341\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.7959 - accuracy: 0.4533\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.7644 - accuracy: 0.4780\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.7356 - accuracy: 0.4918\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.7087 - accuracy: 0.5110\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5357\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.5714\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6209\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6648\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7143\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7500\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7637\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7912\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.8214\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8407\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8846\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8846\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.9011\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.9011\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.9038\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.9121\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8516\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8764\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8791\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8929\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8956\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8901\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8874\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8956\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8819\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.9176\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.9038\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.9148\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.9093\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8874\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.9093\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.9286\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.9258\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.9121\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8379\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8791\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.8929\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8736\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8764\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9011\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9176\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9148\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.9176\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.9176\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.9121\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9231\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.9011\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.6978\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8407\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8956\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.9093\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.9011\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9093\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.9121\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.9038\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.9038\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.9121\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9148\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.9176\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.9148\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.9176\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9286\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.9093\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.9313\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.8984\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9011\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.9121\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.9121\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9148\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9203\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.9148\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.9148\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.1580 - accuracy: 0.5082\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8049\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.9038\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.9121\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8901\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.8334 - accuracy: 0.6099\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8324\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8681\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.9038\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9148\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.9066\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9148\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9286\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9231\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9231\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9286\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9258\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9341\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9258\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9286\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9203\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9368\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9341\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8132\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.9148\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9258\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.9203\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8709\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9203\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9148\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9093\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9286\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9203\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9176\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9231\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.9011\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7308\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8791\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8901\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8929\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8901\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8819\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8846\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8901\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8956\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8764\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8901\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.9011\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8901\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8929\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.9066\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8956\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8929\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.8709\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8489\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8929\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.9011\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8984\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8764\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9093\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.6896\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7912\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8874\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.9011\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.9066\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6484\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6456\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8791\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.9011\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8984\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.9093\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9093\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9066\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.9011\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9038\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9011\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9148\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9148\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.8874\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9121\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.9148\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8297\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.7750 - accuracy: 0.5742\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.4890\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.9011\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.9066\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.9038\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.9093\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2391 - accuracy: 0.9066\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9011\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9093\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8846\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.8874\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.8956\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8984\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9011\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8901\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 5.0851 - accuracy: 0.6703\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7363\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8544\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8819\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.8681\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.0747 - accuracy: 0.8462\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8516\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.9121\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8956\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.8984\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9038\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9038\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9011\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.9011\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9093\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.9066\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9011\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8984\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.7995\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8736\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8984\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8764\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8874\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.9066\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.9066\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.9066\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8984\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.8984\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8984\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.9011\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8764\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9451\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.5766 - accuracy: 0.7033\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 5.0851 - accuracy: 0.6703\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.5766 - accuracy: 0.7033\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.8628 - accuracy: 0.5440\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7720\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8599\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8654\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8874\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8956\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8929\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8901\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8956\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8901\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.9066\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.9093\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.9038\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.9011\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.8984\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9066\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.9038\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.9066\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.9121\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9038\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8984\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8736\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.8929\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.9038\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9121\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.9038\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.9066\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8238 - accuracy: 0.8901\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.6813\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6016\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7088\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8736\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8846\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8984\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.9066\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.9066\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.9093\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9011\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9148\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9176\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9148\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.9066\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9148\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.9093\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9121\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9148\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7995\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.9011\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8956\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.9066\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.9038\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.9066\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.9038\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9121\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.9176\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9093\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.9121\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9148\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8791\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6621\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6538\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7033\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8104\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.9011\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.9121\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.9066\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.8984\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.9148\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8654\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.8269\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.9148\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9011\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.8901\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8791\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.9121\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.9121\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9121\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9231\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9176\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9231\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9258\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9231\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9231\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9203\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2315 - accuracy: 0.9203\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9121\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9121\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.9093\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.9011\n",
            "20\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7225\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8049\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.7940\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.7830\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.7912\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8132\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8297\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8352\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8379\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.9093\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.9176\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.9121\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.9176\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.9148\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.9231\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.9203\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.9176\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.9121\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.9148\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.9176\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.9203\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.9258\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.9121\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.9148\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2896 - accuracy: 0.9203\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.9176\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.9176\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.9176\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.9203\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.9231\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.9011\n",
            "20\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7657 - accuracy: 0.5495\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6978\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7582\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7885\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8214\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8407\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8516\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8516\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8571\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8709\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8709\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8736\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8681\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8819\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8819\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8791\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8819\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8874\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8791\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8874\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8819\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8846\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8846\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8901\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8901\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8929\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8956\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.8874\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3036 - accuracy: 0.8956\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8819\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8791\n",
            "20\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a956c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "20\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.7115\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7418\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7885\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.8159\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.8049\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7995\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8132\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8297\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8214\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8297\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8324\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8379\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8352\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.8379\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8407\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8434\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8462\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8489\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8516\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8516\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8599\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8599\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8571\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8654\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8654\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8654\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8626\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8626\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8654\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8654\n",
            "WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53af528ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8681\n",
            "20\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "WARNING:tensorflow:7 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53ae3260d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5766 - accuracy: 0.7033\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a83ea6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.6236\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7555\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8654\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.9011\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.9093\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.9176\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9093\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9093\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9121\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9038\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9148\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9121\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9148\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9148\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9148\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9121\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9176\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9148\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9203\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9203\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9176\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1758 - accuracy: 0.9148\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9176\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9176\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9176\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 0.9148\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9148\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9176\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9148\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9176\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a83ead08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.9011\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "WARNING:tensorflow:9 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a9b12a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7139 - accuracy: 0.4286\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.7088 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8736 - accuracy: 0.6456\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.7473\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.7857\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8269\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8407\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8791\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8901\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8819\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.8819\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.8874\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.8984\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.9011\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9121\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8956\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.9093\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.9011\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.9011\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.9066\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.9066\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.8956\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.9066\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.8956\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.9148\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9231\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.9231\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9066\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9066\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9121\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9176\n",
            "WARNING:tensorflow:10 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53a5197730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9780\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "WARNING:tensorflow:11 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d41c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.5766 - accuracy: 0.7033\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d41c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d8a1d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0851 - accuracy: 0.6703\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d646268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.4679 - accuracy: 0.3791\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d020510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.0490 - accuracy: 0.4066\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.5989\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7363\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.8022\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.8352\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8571\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8544\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8489\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8489\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8462\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8571\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8544\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8626\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8654\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8764\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8846\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.8901\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.8929\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8956\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2618 - accuracy: 0.8956\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.8984\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.9038\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8654\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.8846\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8599\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8489\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8901\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.9093\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9093\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d3b7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8571\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d3b78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53aec1f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0851 - accuracy: 0.6703\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.7632 - accuracy: 0.6264\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53ae326ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6107 - accuracy: 0.5714\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53adb52ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "64\n",
            "64\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53adb52510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5766 - accuracy: 0.7033\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53af4f2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53ae096400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0851 - accuracy: 0.6703\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7249 - accuracy: 0.6264\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6264\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6578 - accuracy: 0.7115\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.7033\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6264\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6264\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6264\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.6264\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.6264\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.6264\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.6264\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.6566\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7582\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7747\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7995\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.8187\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8379\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8599\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8599\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8654\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8654\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8764\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8901\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8901\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8846\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8956\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.9093\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.9121\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.9011\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539cfb1d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8901\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8479 - accuracy: 0.6209\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d838268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "64\n",
            "32\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d13a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5766 - accuracy: 0.7033\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6360 - accuracy: 0.6346\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d31dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1192 - accuracy: 0.5385\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 6.1446 - accuracy: 0.6016\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539cf0f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0851 - accuracy: 0.6703\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5517 - accuracy: 0.3736\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d31d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.7139 - accuracy: 0.4286\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.6209\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.6209\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.6209\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6209\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6209\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6209\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6209\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.6209\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6209\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6209\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.6703\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.6209\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.6209\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7637\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7995\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7198\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7308\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8681\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8764\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8819\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.9011\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8984\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.9011\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2957 - accuracy: 0.9066\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.9038\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9121\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2337 - accuracy: 0.9093\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9176\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.9066\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9203\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f539d31dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.9451\n",
            "64\n",
            "64\n",
            "32\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.2717 - accuracy: 0.5934\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f53ae3adc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5766 - accuracy: 0.7033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-807fe847b3e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f53ad176eb8>, as the constructor either does not set or modifies parameter layers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNWj9hA_Sjf2",
        "outputId": "2f04a7d7-6923-4704-9ada-273ad71635b6"
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'sigmoid',\n",
              " 'batch_size': 50,\n",
              " 'epochs': 30,\n",
              " 'layers': [64, 64, 32]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi3kYA5SQgYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4e0f4d-0c7f-404b-fdb2-7f2c69001349"
      },
      "source": [
        "backend.clear_session()\r\n",
        "class_model = models.Sequential([\r\n",
        "  Dense(64, input_shape=[x_train.shape[1]], activation = 'sigmoid'),\r\n",
        "  Dense(64, activation='sigmoid'),\r\n",
        "  Dense(32, activation='sigmoid'),\r\n",
        "  Dense(1)\r\n",
        "])\r\n",
        "class_model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                1984      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 8,257\n",
            "Trainable params: 8,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw-JHt8ERQtZ"
      },
      "source": [
        "class_model.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=['accuracy'])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vadwbjF8Rdtp",
        "outputId": "65958474-26b1-4e14-9d6c-407749647799"
      },
      "source": [
        "history = class_model.fit(x_train,y_encoded_train, epochs=50, validation_data=(x_test,y_encoded_test), batch_size=50)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.7676 - accuracy: 0.4835 - val_loss: 0.6326 - val_accuracy: 0.6754\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6154 - val_loss: 0.6026 - val_accuracy: 0.6754\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.7692 - val_loss: 0.5857 - val_accuracy: 0.6842\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.6176 - val_loss: 0.5274 - val_accuracy: 0.6754\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7165 - val_loss: 0.5133 - val_accuracy: 0.8684\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.6659 - val_loss: 0.4541 - val_accuracy: 0.6754\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7516 - val_loss: 0.4402 - val_accuracy: 0.9123\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8989 - val_loss: 0.3785 - val_accuracy: 0.8860\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8725 - val_loss: 0.3383 - val_accuracy: 0.9035\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8879 - val_loss: 0.3048 - val_accuracy: 0.9123\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8835 - val_loss: 0.3688 - val_accuracy: 0.9035\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8989 - val_loss: 0.2374 - val_accuracy: 0.8947\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3146 - accuracy: 0.8879 - val_loss: 0.2854 - val_accuracy: 0.9211\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.9011 - val_loss: 0.2069 - val_accuracy: 0.9123\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.9033 - val_loss: 0.2140 - val_accuracy: 0.9035\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.8901 - val_loss: 0.5892 - val_accuracy: 0.8421\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8813 - val_loss: 0.2415 - val_accuracy: 0.9035\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 0.8967 - val_loss: 0.2158 - val_accuracy: 0.9123\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.9077 - val_loss: 0.4289 - val_accuracy: 0.9211\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.9099 - val_loss: 0.4025 - val_accuracy: 0.9211\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6659 - val_loss: 0.6884 - val_accuracy: 0.6579\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8703 - val_loss: 0.2651 - val_accuracy: 0.8772\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.8462 - val_loss: 0.2782 - val_accuracy: 0.9386\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8659 - val_loss: 0.2831 - val_accuracy: 0.9123\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8945 - val_loss: 0.2165 - val_accuracy: 0.9211\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.9033 - val_loss: 0.2183 - val_accuracy: 0.9123\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.9033 - val_loss: 0.2055 - val_accuracy: 0.9211\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2605 - accuracy: 0.9077 - val_loss: 0.7703 - val_accuracy: 0.8421\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7912 - val_loss: 0.4926 - val_accuracy: 0.9123\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.9055 - val_loss: 0.2699 - val_accuracy: 0.9211\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2831 - accuracy: 0.8945 - val_loss: 0.2469 - val_accuracy: 0.9211\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.9077 - val_loss: 0.2474 - val_accuracy: 0.9123\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.9011 - val_loss: 0.2200 - val_accuracy: 0.9035\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.8989 - val_loss: 0.3377 - val_accuracy: 0.9211\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.8989 - val_loss: 0.3162 - val_accuracy: 0.9035\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.8967 - val_loss: 0.3555 - val_accuracy: 0.9035\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.8967 - val_loss: 0.3251 - val_accuracy: 0.9035\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.9011 - val_loss: 0.3727 - val_accuracy: 0.9123\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.8791 - val_loss: 0.3633 - val_accuracy: 0.9123\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.8967 - val_loss: 0.3370 - val_accuracy: 0.9211\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9011 - val_loss: 0.3365 - val_accuracy: 0.9123\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2170 - accuracy: 0.9011 - val_loss: 0.3024 - val_accuracy: 0.9211\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.9033 - val_loss: 0.3040 - val_accuracy: 0.9123\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.9099 - val_loss: 0.3393 - val_accuracy: 0.9211\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2245 - accuracy: 0.9055 - val_loss: 0.3392 - val_accuracy: 0.9123\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9055 - val_loss: 0.3379 - val_accuracy: 0.9123\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.9033 - val_loss: 0.3214 - val_accuracy: 0.9035\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8989 - val_loss: 0.1933 - val_accuracy: 0.9298\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8989 - val_loss: 0.3125 - val_accuracy: 0.9123\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.9099 - val_loss: 0.1967 - val_accuracy: 0.9123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Fh95cP7aRh9O",
        "outputId": "80986db7-05ed-4158-f32d-5fcfe902a541"
      },
      "source": [
        "plt.plot(history.history['accuracy'])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f53a52379b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "q5hVqgRnS6a0",
        "outputId": "502123dc-9df4-4d35-d65e-efd302a54879"
      },
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f53a96a5438>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8IWw5arTN4s",
        "outputId": "63e31075-bf60-4c68-ddb3-ce8a88c5455c"
      },
      "source": [
        "class_model.evaluate(x_test,y_encoded_test, batch_size=50)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19666500389575958, 0.9122806787490845]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR2sNt5pWFYd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}